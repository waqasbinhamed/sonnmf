{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "from sonnmf.main import sonnmf\n",
    "from sonnmf.old.main import sonnmf as sonnmf_old\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(filepath, W, H, fscores, gscores, hscores, total_scores):\n",
    "    with open(filepath, 'wb') as fout:\n",
    "        np.savez_compressed(fout, W=W, H=H, fscores=fscores, gscores=gscores, hscores=hscores, total_scores=total_scores)\n",
    "\n",
    "def load_results(filepath):\n",
    "    data = np.load(filepath)\n",
    "    return data['W'], data['H'], data['fscores'], data['gscores'], data['hscores'], data['total_scores']\n",
    "\n",
    "def save_results_old(filepath, W, H, fscores, gscores, total_scores):\n",
    "    with open(filepath, 'wb') as fout:\n",
    "        np.savez_compressed(fout, W=W, H=H, fscores=fscores, gscores=gscores, total_scores=total_scores)\n",
    "\n",
    "def load_results_old(filepath):\n",
    "    data = np.load(filepath)\n",
    "    return data['W'], data['H'], data['fscores'], data['gscores'], data['total_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = \"../saved_models/runtime_comparison/results.csv\"\n",
    "\n",
    "if not os.path.exists(csv_filename):\n",
    "    with open(csv_filename, 'w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['Dataset' ,'Method', 'Time Taken', 'Save Filepath'])\n",
    "\n",
    "    #  with open(csv_filename, 'a', newline='') as csv_file:\n",
    "    #                 csv_writer = csv.writer(csv_file)\n",
    "    #                 csv_writer.writerow(['Dataset' ,'Method', 'Time Taken', 'Save Filepath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_solvers = ['proximal_avg_with_penalty_func', 'proximal_avg_with_indicator_func', 'admm', 'nesterov_smoothing', 'subgradient']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## synthetic (r=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = '../datasets/synthetic_data.npz'\n",
    "ini_filepath = '../saved_models/synthetic/r{}_ini.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(data_filepath):\n",
    "    data = np.load(data_filepath)\n",
    "    M = data['M']\n",
    "    W_true = data['W_true']\n",
    "    H_true = data['H_true']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'sythetic_r8'\n",
    "m, n = M.shape\n",
    "r = 8\n",
    "\n",
    "max_iters = 1000\n",
    "_lam = 1e-6\n",
    "_gamma = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(ini_filepath.format(r)):\n",
    "    data = np.load(ini_filepath.format(r))\n",
    "    ini_W = data['ini_W']\n",
    "    ini_H = data['ini_H']\n",
    "else:\n",
    "    ini_W = np.random.rand(m, r)\n",
    "    ini_H = np.random.rand(r, n)\n",
    "    with open(ini_filepath.format(r), 'wb') as fout:\n",
    "        np.savez_compressed(fout, ini_W=ini_W, ini_H=ini_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proximal averaging with penalty term\n",
    "\n",
    "save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solvers[0]}.npz'\n",
    "\n",
    "if not os.path.exists(save_filepath):\n",
    "    start_time = time.time()\n",
    "    W, H, fscores, gscores, hscores, total_scores = sonnmf(M, ini_W.copy(), ini_H.copy(), lam=_lam, gamma=_gamma, itermax=max_iters, W_update_iters=10, early_stop=True, verbose=False)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_results(save_filepath, W, H, fscores, gscores, hscores, total_scores)\n",
    "\n",
    "    with open(csv_filename, 'a', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow([dataset_name , w_solvers[0], time_taken, save_filepath])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w_solver in w_solvers[1:]:\n",
    "    save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solver}.npz'\n",
    "\n",
    "    if not os.path.exists(save_filepath):\n",
    "        start_time = time.time()\n",
    "        W, H, fscores, gscores, total_scores = sonnmf_old(M, ini_W.copy(), ini_H.copy(), lam=_lam, w_update_method=w_solver, itermax=max_iters, W_update_iters=10, early_stop=True, verbose=False)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_results_old(save_filepath, W, H, fscores, gscores, total_scores)\n",
    "\n",
    "        with open(csv_filename, 'a', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow([dataset_name , w_solver, time_taken, save_filepath])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_solvers = ['proximal_avg_with_penalty_func', 'proximal_avg_with_indicator_func', 'admm', 'nesterov_smoothing']\n",
    "linech = ['-', '--', '-.', ':']\n",
    "\n",
    "save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solvers[0]}.npz'\n",
    "_, _, fscores, gscores, _, total_scores = load_results(save_filepath)\n",
    "total_scores = fscores + _lam * gscores\n",
    "plt.plot(total_scores[np.insert(np.abs(total_scores[1:] - total_scores[:-1]) / total_scores[:-1] >= 1e-6, 0, True)], linech[0])\n",
    "\n",
    "for i in range(1, len(w_solvers)):\n",
    "    w_solver = w_solvers[i]\n",
    "    save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solver}.npz'\n",
    "    _, _, fscores, gscores, total_scores = load_results_old(save_filepath)\n",
    "    # plt.plot(total_scores)\n",
    "    plt.plot(total_scores[np.insert(np.abs(total_scores[1:] - total_scores[:-1]) / total_scores[:-1] >= 1e-6, 0, True)], linech[i])\n",
    "\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend(['Proximal Avg. w/ penalty', 'Proximal Avg. w/ indicator', 'ADMM', 'Nesterov Smoothing'])\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel(r'$F(W, H) = \\frac{1}{2} \\| WH - M \\|_F^2 + \\lambda \\sum_{i \\neq j} \\| w_i - w_j \\|_2$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'F_clipped_{dataset_name}.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jasper region 1 (8 * 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = '../datasets/jasper_region_1.npz'\n",
    "ini_filepath = '../saved_models/jasper_region_1/r{}_ini.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.load(data_filepath)['X']\n",
    "M = M.astype(np.float64)\n",
    "m, n = M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'jasper_region_1'\n",
    "m, n = M.shape\n",
    "r = n\n",
    "\n",
    "max_iters = 2000\n",
    "_lam = 40000\n",
    "_gamma = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(ini_filepath.format(r)):\n",
    "    data = np.load(ini_filepath.format(r))\n",
    "    ini_W = data['ini_W']\n",
    "    ini_H = data['ini_H']\n",
    "else:\n",
    "    ini_W = np.random.rand(m, r)\n",
    "    ini_H = np.random.rand(r, n)\n",
    "    with open(ini_filepath.format(r), 'wb') as fout:\n",
    "        np.savez_compressed(fout, ini_W=ini_W, ini_H=ini_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proximal averaging with penalty term\n",
    "\n",
    "save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solvers[0]}.npz'\n",
    "\n",
    "if not os.path.exists(save_filepath):\n",
    "    start_time = time.time()\n",
    "    W, H, fscores, gscores, hscores, total_scores = sonnmf(M, ini_W.copy(), ini_H.copy(), lam=_lam, gamma=_gamma, itermax=max_iters, W_update_iters=10, early_stop=True, verbose=False)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_results(save_filepath, W, H, fscores, gscores, hscores, total_scores)\n",
    "\n",
    "    with open(csv_filename, 'a', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow([dataset_name , w_solvers[0], time_taken, save_filepath])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w_solver in w_solvers[1:]:\n",
    "    save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solver}.npz'\n",
    "\n",
    "    if not os.path.exists(save_filepath):\n",
    "        start_time = time.time()\n",
    "        W, H, fscores, gscores, total_scores = sonnmf_old(M, ini_W.copy(), ini_H.copy(), lam=_lam, w_update_method=w_solver, itermax=max_iters, W_update_iters=10, early_stop=True, verbose=False)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_results_old(save_filepath, W, H, fscores, gscores, total_scores)\n",
    "\n",
    "        with open(csv_filename, 'a', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow([dataset_name , w_solver, time_taken, save_filepath])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_solvers = ['proximal_avg_with_penalty_func', 'proximal_avg_with_indicator_func', 'admm', 'nesterov_smoothing']\n",
    "linech = ['-', '--', '-.', ':']\n",
    "\n",
    "save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solvers[0]}.npz'\n",
    "_, _, fscores, gscores, _, total_scores = load_results(save_filepath)\n",
    "total_scores = fscores + _lam * gscores\n",
    "plt.plot(total_scores[np.insert(np.abs(total_scores[1:] - total_scores[:-1]) / total_scores[:-1] >= 1e-6, 0, True)], linech[0])\n",
    "\n",
    "for i in range(1, len(w_solvers)):\n",
    "    w_solver = w_solvers[i]\n",
    "    save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solver}.npz'\n",
    "    _, _, fscores, gscores, total_scores = load_results_old(save_filepath)\n",
    "    # plt.plot(total_scores)\n",
    "    plt.plot(total_scores[np.insert(np.abs(total_scores[1:] - total_scores[:-1]) / total_scores[:-1] >= 1e-6, 0, True)], linech[i])\n",
    "\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend(['Proximal Avg. w/ penalty', 'Proximal Avg. w/ indicator', 'ADMM', 'Nesterov Smoothing'])\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel(r'$F(W, H) = \\frac{1}{2} \\| WH - M \\|_F^2 + \\lambda \\sum_{i \\neq j} \\| w_i - w_j \\|_2$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'F_clipped_{dataset_name}.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jasper full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = '../datasets/jasper_full.npz'\n",
    "ini_filepath = '../saved_models/jasper_fullr{}_ini.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.load(data_filepath)['X']\n",
    "M = M.astype(np.float64)\n",
    "m, n = M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'jasper_full'\n",
    "m, n = M.shape\n",
    "r = n\n",
    "\n",
    "max_iters = 1000\n",
    "_lam = 1000000\n",
    "_gamma = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(ini_filepath.format(r)):\n",
    "    data = np.load(ini_filepath.format(r))\n",
    "    ini_W = data['ini_W']\n",
    "    ini_H = data['ini_H']\n",
    "else:\n",
    "    ini_W = np.random.rand(m, r)\n",
    "    ini_H = np.random.rand(r, n)\n",
    "    with open(ini_filepath.format(r), 'wb') as fout:\n",
    "        np.savez_compressed(fout, ini_W=ini_W, ini_H=ini_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proximal averaging with penalty term\n",
    "\n",
    "save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solvers[0]}.npz'\n",
    "\n",
    "if not os.path.exists(save_filepath):\n",
    "    start_time = time.time()\n",
    "    W, H, fscores, gscores, hscores, total_scores = sonnmf(M, ini_W.copy(), ini_H.copy(), lam=_lam, gamma=_gamma, itermax=max_iters, W_update_iters=10, early_stop=True, verbose=False)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_results(save_filepath, W, H, fscores, gscores, hscores, total_scores)\n",
    "\n",
    "    with open(csv_filename, 'a', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow([dataset_name , w_solvers[0], time_taken, save_filepath])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w_solver in w_solvers[1:]:\n",
    "    save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solver}.npz'\n",
    "\n",
    "    if not os.path.exists(save_filepath):\n",
    "        start_time = time.time()\n",
    "        W, H, fscores, gscores, total_scores = sonnmf_old(M, ini_W.copy(), ini_H.copy(), lam=_lam, w_update_method=w_solver, itermax=max_iters, W_update_iters=10, early_stop=True, verbose=False)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_results_old(save_filepath, W, H, fscores, gscores, total_scores)\n",
    "\n",
    "        with open(csv_filename, 'a', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow([dataset_name , w_solver, time_taken, save_filepath])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_solvers = ['proximal_avg_with_penalty_func', 'proximal_avg_with_indicator_func', 'admm', 'nesterov_smoothing']\n",
    "linech = ['-', '--', '-.', ':']\n",
    "\n",
    "save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solvers[0]}.npz'\n",
    "_, _, fscores, gscores, _, total_scores = load_results(save_filepath)\n",
    "total_scores = fscores + _lam * gscores\n",
    "plt.plot(total_scores[np.insert(np.abs(total_scores[1:] - total_scores[:-1]) / total_scores[:-1] >= 1e-6, 0, True)], linech[0])\n",
    "\n",
    "for i in range(1, len(w_solvers)):\n",
    "    w_solver = w_solvers[i]\n",
    "    save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solver}.npz'\n",
    "    _, _, fscores, gscores, total_scores = load_results_old(save_filepath)\n",
    "    # plt.plot(total_scores)\n",
    "    plt.plot(total_scores[np.insert(np.abs(total_scores[1:] - total_scores[:-1]) / total_scores[:-1] >= 1e-6, 0, True)], linech[i])\n",
    "\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend(['Proximal Avg. w/ penalty', 'Proximal Avg. w/ indicator', 'ADMM', 'Nesterov Smoothing'])\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel(r'$F(W, H) = \\frac{1}{2} \\| WH - M \\|_F^2 + \\lambda \\sum_{i \\neq j} \\| w_i - w_j \\|_2$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'F_clipped_{dataset_name}.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## urban full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = '../datasets/urban_full.npz'\n",
    "ini_filepath = '../saved_models/urban_fullr{}_ini.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.load(data_filepath)['X']\n",
    "M = M.astype(np.float64)\n",
    "m, n = M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'urban_full'\n",
    "m, n = M.shape\n",
    "r = n\n",
    "\n",
    "max_iters = 1000\n",
    "_lam = 1000000\n",
    "_gamma = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(ini_filepath.format(r)):\n",
    "    data = np.load(ini_filepath.format(r))\n",
    "    ini_W = data['ini_W']\n",
    "    ini_H = data['ini_H']\n",
    "else:\n",
    "    ini_W = np.random.rand(m, r)\n",
    "    ini_H = np.random.rand(r, n)\n",
    "    with open(ini_filepath.format(r), 'wb') as fout:\n",
    "        np.savez_compressed(fout, ini_W=ini_W, ini_H=ini_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proximal averaging with penalty term\n",
    "\n",
    "save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solvers[0]}.npz'\n",
    "\n",
    "if not os.path.exists(save_filepath):\n",
    "    start_time = time.time()\n",
    "    W, H, fscores, gscores, hscores, total_scores = sonnmf(M, ini_W.copy(), ini_H.copy(), lam=_lam, gamma=_gamma, itermax=max_iters, W_update_iters=10, early_stop=True, verbose=False)\n",
    "    time_taken = time.time() - start_time\n",
    "    save_results(save_filepath, W, H, fscores, gscores, hscores, total_scores)\n",
    "\n",
    "    with open(csv_filename, 'a', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow([dataset_name , w_solvers[0], time_taken, save_filepath])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w_solver in w_solvers[1:]:\n",
    "    save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solver}.npz'\n",
    "\n",
    "    if not os.path.exists(save_filepath):\n",
    "        start_time = time.time()\n",
    "        W, H, fscores, gscores, total_scores = sonnmf_old(M, ini_W.copy(), ini_H.copy(), lam=_lam, w_update_method=w_solver, itermax=max_iters, W_update_iters=10, early_stop=True, verbose=False)\n",
    "        time_taken = time.time() - start_time\n",
    "        save_results_old(save_filepath, W, H, fscores, gscores, total_scores)\n",
    "\n",
    "        with open(csv_filename, 'a', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow([dataset_name , w_solver, time_taken, save_filepath])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_solvers = ['proximal_avg_with_penalty_func', 'proximal_avg_with_indicator_func', 'admm', 'nesterov_smoothing']\n",
    "linech = ['-', '--', '-.', ':']\n",
    "\n",
    "save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solvers[0]}.npz'\n",
    "_, _, fscores, gscores, _, total_scores = load_results(save_filepath)\n",
    "total_scores = fscores + _lam * gscores\n",
    "plt.plot(total_scores[np.insert(np.abs(total_scores[1:] - total_scores[:-1]) / total_scores[:-1] >= 1e-6, 0, True)], linech[0])\n",
    "\n",
    "for i in range(1, len(w_solvers)):\n",
    "    w_solver = w_solvers[i]\n",
    "    save_filepath = f'../saved_models/runtime_comparison/{dataset_name}_{w_solver}.npz'\n",
    "    _, _, fscores, gscores, total_scores = load_results_old(save_filepath)\n",
    "    # plt.plot(total_scores)\n",
    "    plt.plot(total_scores[np.insert(np.abs(total_scores[1:] - total_scores[:-1]) / total_scores[:-1] >= 1e-6, 0, True)], linech[i])\n",
    "\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend(['Proximal Avg. w/ penalty', 'Proximal Avg. w/ indicator', 'ADMM', 'Nesterov Smoothing'])\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel(r'$F(W, H) = \\frac{1}{2} \\| WH - M \\|_F^2 + \\lambda \\sum_{i \\neq j} \\| w_i - w_j \\|_2$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'F_clipped_{dataset_name}.jpg')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sonnmf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
